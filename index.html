
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5.0, minimum-scale=0.2">


<head>
    <link rel="stylesheet" href="bootstrap.min.css">
    <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101296995);</script>
    <script async src="//static.getclicky.com/js"></script>    

    <script>
        try{
            if (window.screen.width < 700) {
                setActiveStyleSheet("jemdoc_mobile.css"); 
            } 
            else if(/iPad/i.test(navigator.userAgent)){ 
                setActiveStyleSheet("jemdoc.css"); 
            } 
            else{
                setActiveStyleSheet("jemdoc.css"); 
            } 
        } 
        catch(e){} 

        function setActiveStyleSheet(filename){
            document.write("<link href="+filename+" rel=stylesheet>");
        }

        function checkFilter(type, li) {
            if (type == "All") {
                return true
            }
            else if (type == "First-authored") {
                res = li.getAttribute("first_authored")
                return res
            }
            else {
                cate = li.getAttribute("category")
                if (!cate) {
                    return false
                }
                items = cate.split(',')
                for (j = 0; j < items.length; j++) {
                    console.log(items[j])
                    if (type.toUpperCase() == items[j].toUpperCase()) {
                        return true
                    }
                }
                return false
            }
        }

        function filterPub(type) {
            ul = document.getElementById("publications")
            li = ul.getElementsByTagName("li")
            for (i = 0; i < li.length; i++) {
                if (!checkFilter(type, li[i])) {
                    li[i].style.display = "none";
                }
                else {
                    li[i].style.display = ""
                }
            }
            // change the button color
            bts = document.getElementsByClassName("filter")
            for (k = 0; k < bts.length; k++) {
                if (bts[k].textContent == type) {
                    bts[k].style.setProperty("--color", "#000")
                    bts[k].style.setProperty("--border", "#000")
                    // bts[k].style.color = "#000"
                }
                else {
                    bts[k].style.setProperty("--color", "#a0a0a0")
                    bts[k].style.setProperty("--border", "#d3d3d3")
                    // bts[k].style.color = "#a0a0a0"
                }
            }
        }

    </script>

    <script>
        // import data from './bibtex.json' assert { type: 'json' };

        function getBibTex(key) {
            prompt("You can copy the text manually.", data[key]);
        }
    </script>

    <link rel="shortcut icon" href="fig/pku.png">
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="keywords" content="Yuan Zhang, 张袁, Alibaba DAMO, Peking University, PKU, Hohai University, HHU">
    <meta name="description" content="Homepage of Yuan Zhang">
    <!-- <link rel="stylesheet" href="jemdoc.css" type="text/css" />
    <link rel="stylesheet" media="screen and (max-width:700px)" href="jemdoc_mobile.css" type="text/css" />
    <link rel="stylesheet" media="screen and (max-width:700px)" href="jemdoc.css" type="text/css" /> -->
    <title>Homepage of Yuan Zhang</title>
</head>

<body>
    <div id="layout-content" style="margin-top:40px">
        <table>
            <tbody>
                <tr>
                    <td width="60%" class="tdw" border="0">
                        <h1>Yuan Zhang</h1>
                        <p>
                            Ph.D. Candidate <br>

			    Center on Frontiers of Computing Studies, Peking University
                        </p>
                        <p>
                            Email: <a href="mailto:zhangyuan@alumni.pku.edu.cn"> zhangyuan [at] alumni.pku.edu.cn</a>
                        </p>
                        <p>
                            <a href="https://github.com/Gumpest"><img src="fig/github.png" class="icon"></a>&nbsp;&nbsp;
                            <a href="https://scholar.google.com/citations?user=dXj1WskAAAAJ&hl=en"><img src="fig/google_scholar.png" class="icon"></a>&nbsp;&nbsp;
			    <a href="https://x.com/YuanZhang_PKU"><img src="fig/X.png" class="icon"></a>
                        </p>
                    </td>
                    <td width="15%"><img src="fig/img3.jpeg" border="0" width="100%"></br></td>
			        
		<tr>
	</tbody>
</table>


<h2 style="margin-top: -1em;">Biography</h2>
<p>
    <div style="text-align:justify"> 
	Yuan Zhang is a Ph.D. Candidate at <a href="https://english.pku.edu.cn/">Peking University (PKU)</a>, 
	advised by Prof. Shanghang Zhang and Prof. Kuan Cheng. Previously, he received his M.Eng. degree from
	Peking University and B.Eng. degree from <a href="https://en.hhu.edu.cn/">Hohai University (HHU)</a>. 
	He used to intern at SenseTime Research, Alibaba (DAMO Academy), and ByteDance (Seed Foundation Model). <br />
	    
    </div>
</p>
<p>His major research interests lie within efficient machine learning algorithms, like
	<ul>
		<li style="margin-top: 0.2em">Efficient AI (KD, Pruning, Quantization)</li>
		<li style="margin-top: 0.2em">Multimodal Large Language Model</li>
	</ul>
</p>

<h2 style="margin-top: -1em;">Education</h2>
	    
<table style="margin-top: 0em;" width="100%" align="center" border="0" cellpadding="5">
	<tbody>
		<tr>
			<td width="75%" valign="middle">
				<papertitle><a href="https://english.pku.edu.cn/">Peking University (PKU)</a>, Beijing, China</papertitle>
				<div style="display: flex; justify-content: space-between; font-style: italic;">
				    <div> PhD Candidate at <a href="https://cfcs.pku.edu.cn/index.htm">Center on Frontiers of Computing Studies.</a>
					  <br> Sep. 2024 – Jun. 2028 </br>
				    </div>	
				</div>
				<ul>
				    <li style="margin-top: 0.3em">
					Rank: 5/52 
				    </li>
				    <li style="margin-top: 0.3em">
					Research: Efficiency for Multimodal Large Language Model (MLLM)
				    </li>
				</ul>
				</td>
				<td align="center" style="padding:2px 20px;width:25%;vertical-align:middle"><img src='fig/pku.png' width="60">
			</td>
		</tr>
	</tbody>
</table>

<table style="margin-top: 0em;" width="100%" align="center" border="0" cellpadding="5">
	<tbody>
		<tr>
			<td width="75%" valign="middle">
				<papertitle><a href="https://english.pku.edu.cn/">Peking University (PKU)</a>, Beijing, China</papertitle>
				<div style="display: flex; justify-content: space-between; font-style: italic;">
				    <div> Master Degree.</a>
					  <br> Sep. 2020 – Jun. 2023 </br>
				    </div>	
				</div>
				<ul>
				    <li style="margin-top: 0.3em">
					Rank: 3/110
				    </li>
				    <li style="margin-top: 0.3em">
					National Scholarship of China
				    </li>
				</ul>
				</td>
				<td align="center" style="padding:2px 20px;width:25%;vertical-align:middle"><img src='fig/pku.png' width="60">
			</td>
		</tr>
	</tbody>
</table>

<table style="margin-top: 0em;" width="100%" align="center" border="0" cellpadding="5">
	<tbody>
		<tr>
			<td width="75%" valign="middle">
				<papertitle><a href="https://en.hhu.edu.cn/">Hohai University (HHU)</a>, Nanjing, China</papertitle>
				<div style="display: flex; justify-content: space-between; font-style: italic;">
				    <div> Bachelor Degree.</a>
					  <br> Sep. 2016 – Jun. 2020 </br>
				    </div>	
				</div>
				<ul>
				    <li style="margin-top: 0.3em">
					Rank: 1/112
				    </li>
				    <li style="margin-top: 0.3em">
					National Scholarship of China
				    </li>
				</ul>
				</td>
				<td align="center" style="padding:2px 20px;width:25%;vertical-align:middle"><img src='fig/hhu.png' width="60">
			</td>
		</tr>
	</tbody>
</table>
	    
<h2 style="margin-top: -1em;">Selected Publications</h2>
First-author: <venue>ICML</venue>x 1, <venue>NeurIPS</venue>x 1, <venue>CVPR</venue>x 1, <venue>ACM MM</venue>x 1 <br><br>

<button class="filter" type="button" onclick="filterPub('All')" style="--color: #000; --border: #000">All</button>&nbsp;
<button class="filter" type="button" onclick="filterPub('First-authored')">First author</button>&nbsp;
<button class="filter" type="button" onclick="filterPub('KD')">Knowledge distillation</button>&nbsp;
<button class="filter" type="button" onclick="filterPub('VLM')">Vision language model</button>&nbsp;

<ul id="publications">
    <li first_authored=true category="VLM">
        <venue>C1</venue><pt>SparseVLM: Visual Token Sparsification for Efficient Vision-Language Model Inference</pt><br>
	  <b>Yuan Zhang</b>, ChunKai Fan, Junpeng Ma, and
	  <span class="more-authors"
	        data-short="7 more authors"
	        data-full="Wenzhao Zheng, Tao Huang, Kuan Cheng, Denis Gudovskiy, Tomoyuki Okuno, Yohei Nakata, Kurt Keutzer,"
	        onclick="toggleAuthors(this)"
	        title="click to view more authors"
	        style="cursor:pointer; color:#1a73e8;">
	    7 more authors,
	  </span> Shanghang Zhang
	  <br>
        <em>International Conference on Machine Learning</em> (<b>ICML</b>), 2025.</em>
        <p>
            <a href="https://arxiv.org/pdf/2410.04417" class="button-59">PDF</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13876321258274905912" class="button-59">Bib</a>
            <a href="https://github.com/Gumpest/SparseVLMs" class="button-59">Code</a>
	    <a href="https://news.panasonic.com/global/zh-CHS/press/en250704-2" class="button-59">Panasonic Press</a>
        </p>
    </li>
    <li first_authored=true category="VLM">
        <venue>C2</venue><pt>Unveiling the Tapestry of Consistency in Large Vision-Language Models</pt><br>
	<b>Yuan Zhang</b>, Fei Xiao, Tao Huang, and
	  <span class="more-authors"
	        data-short="6 more authors"
	        data-full="Chunkai Fan, Hongyuan Dong, Jiawen Li, Jiacong Wang, Kuan Cheng, Shanghang Zhang,"
	        onclick="toggleAuthors(this)"
	        title="click to view more authors"
	        style="cursor:pointer; color:#1a73e8;">
	    6 more authors,
	  </span> Haoyuan Guo
	  <br>
		
        <em>Advances in Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2024.
        <p>
            <a href="https://arxiv.org/abs/2405.14156" class="button-59">PDF</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13876321258274905912" class="button-59">Bib</a>
            <a href="https://github.com/foundation-multimodal-models/ConBench" class="button-59">Code</a>
	    <a href="https://www.bilibili.com/video/BV1E6mtYTEzu/" class="button-59">Video</a>
	    <a href="https://seed.bytedance.com/en/public_papers/unveiling-the-tapestry-of-consistency-in-large-vision-language-models?view_from=research" class="button-59">ByteDance Seed Press</a>
        </p>
    </li>
    <li first_authored=true category="KD">
        <venue>C3</venue><pt>FreeKD: Knowledge Distillation via Semantic Frequency Prompt</pt><br>
        <b>Yuan Zhang</b><g>, Tao Huang, Jiaming Liu, Tao Jiang, Kuan Cheng, Shanghang Zhang</g><br />
        <em>Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2024.</em>
        <p>
            <a href="https://arxiv.org/pdf/2311.12079.pdf" class="button-59">PDF</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13876321258274905912" class="button-59">Bib</a>
	    <a href="https://github.com/Gumpest/FreeKD" class="button-59">Code</a>
        </p>
    </li>
    <li first_authored=true category="KD">
        <venue>C4</venue><pt>Avatar Knowledge Distillation: Self-ensemble Teacher Paradigm with Uncertainty</pt><br>
        <b>Yuan Zhang</b><g>, Weihua Chen, Yichen Lu, Tao Huang, Xiuyu Sun, Jian Cao</g><br>
        <em>ACM International Conference on Multimedia</em> (<b>ACM MM</b>), 2023.
        <p>
		<a href="https://dl.acm.org/doi/pdf/10.1145/3581783.3611788" class="button-59">PDF</a>
		<a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=9322121606680381236" class="button-59">Bib</a>
		<a class="button-59" href="https://github.com/Gumpest/AvatarKD">Code</a>
		<a href="https://youtu.be/gzBE7ZdvJiM" class="button-59">Video</a>
        </p>
    </li>
    <li VLM=true category="KD">
        <venue>C5</venue><pt>Distilling Cross-Modal Knowledge via Feature Disentanglement</pt><br>
        <g>Junhong Liu,</g> <b>Yuan Zhang</b><g>, Tao Huang, Wenchao Xu, Renyu Yang</g><br />
        <em>AAAI Conference on Artificial Intelligence</em> (<b>AAAI</b>), 2025.</em>
        <p>
            <a href="https://arxiv.org/pdf/2511.19887" class="button-59">PDF</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13876321258274905912" class="button-59">Bib</a>
	    <a href="https://github.com/Johumliu/FD-CMKD" class="button-59">Code</a>
        </p>
    </li>
    <li VLM=true category="VLM">
        <venue>C6</venue><pt>MoVE-KD: Knowledge Distillation for VLMs with Mixture of Visual Encoders</pt><br>
        <g>Jiajun Cao,</g> <b>Yuan Zhang</b><g>, Tao Huang, Ming Lu, Qizhe Zhang, Ruichuan An, Ningning Ma, Shanghang Zhang</g><br />
        <em>Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.</em>
        <p>
            <a href="https://arxiv.org/pdf/2501.01709" class="button-59">PDF</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13876321258274905912" class="button-59">Bib</a>
	    <a href="https://github.com/hey-cjj/MoVE-KD" class="button-59">Code</a>
        </p>
    </li>
    <li category="KD">
        <venue>C7</venue><pt>Knowledge Diffusion for Distillation</pt><br>
        <g>Tao Huang,</g> <b>Yuan Zhang</b><g>, Mingkai Zheng, Shan You, Fei Wang, Chen Qian, Chang Xu</g><br />
        <em>Advances in Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2023.
        <p>
            <a href="https://arxiv.org/abs/2305.15712" class="button-59">PDF</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=4615443208731882220" class="button-59">Bib</a>
            <a href="https://github.com/hunto/DiffKD" class="button-59">Code</a>
        </p>
    </li>
    <li category="KD">
	<venue>C8</venue><pt>Masked Distillation with Receptive Tokens</pt><br>
	<g>Tao Huang*,</g> <b>Yuan Zhang*</b><g>, Shan You, Fei Wang, Chen Qian, Jian Cao, Chang Xu</g><br>
	<em>International Conference on Learning Representations</em> (<b>ICLR</b>), 2023.</em>
	<p>
		<a class="button-59" href="https://arxiv.org/abs/2205.14589">PDF</a>
		<button class="button-59" onclick="getBibTex('huang2023masked')">Bib</button>
		<a class="button-59" href="https://github.com/hunto/MasKD">Code</a>
		<a href="https://www.bilibili.com/video/BV1LM411T7rA" class="button-59">Video</a>
	</p>
    </li>
</ul>

<h2 style="margin-top: -1em;">Manuscripts</h2>
<ul>
    <li>
        <venue>arXiv</venue><pt>ChainV: Atomic Visual Hints Make Multimodal Reasoning Shorter and Better</pt><br>
        <b>Yuan Zhang</b><g>, Ming Lu, Junwen Pan, Tao Huang, Kuan Cheng, Qi She, Shanghang Zhang</g> <br/>
        <em>arXiv preprint arXiv:2511.17106 (2025).</em>
        <p>
            <a href="https://arxiv.org/pdf/2511.17106" class="button-59">PDF</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13876321258274905912" class="button-59">Bib</a>
        </p>
    </li>
    <li>
        <venue>arXiv</venue><pt>Loss-Oriented Ranking for Automated Visual Prompting in LVLMs</pt><br>
        <b>Yuan Zhang</b><g>, Chun-Kai Fan, Tao Huang, Ming Lu, Sicheng Yu, Junwen Pan, Kuan Cheng, Qi She, Shanghang Zhang</g> <br/>
        <em>arXiv preprint arXiv:2506.16112 (2025).</em>
        <p>
            <a href="https://www.arxiv.org/pdf/2506.16112" class="button-59">PDF</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13876321258274905912" class="button-59">Bib</a>
        </p>
    </li>
    <li>
        <venue>arXiv</venue><pt>DAMO-YOLO: A Report on Real-Time Object Detection Design</pt><br>
        <g>Xianzhe Xu*, Yiqi Jiang*, Weihua Chen*, Yilun Huang*, </g><b>Yuan Zhang*</b><g>, Xiuyu Sun</g> <br />
        <em>arXiv preprint arXiv:2211.15444 (2022).</em>
        <p>
            <a href="https://arxiv.org/pdf/2211.15444.pdf" class="button-59">PDF</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13876321258274905912" class="button-59">Bib</a>
            <a href="https://github.com/tinyvision/DAMO-YOLO" class="button-59">Code</a>
	    <a href="https://www.bilibili.com/video/BV1hW4y1g7za/" class="button-59">Video</a>
        </p>
    </li>
</ul>


<h2 style="margin-top: -1em;">Research Experience</h2>
	    
<table style="margin-top: 0em;" width="100%" align="center" border="0" cellpadding="5">
	<tbody>
		<tr>
			<td width="75%" valign="middle">
				<papertitle><a href="https://bair.berkeley.edu/"> Berkeley Artificial Intelligence Research Lab (BAIR)</a>, California, USA</papertitle>
				<div style="display: flex; justify-content: space-between; font-style: italic;">
				    <div> Remote Research Intern  (Advisor: <a href="https://wzzheng.net/">Wenzhao Zheng</a>). </a>
					  <br> Sep. 2024 – Dec. 2024 </br>
				    </div>	
				</div>
			        <ul>
			            <li style="margin-top: 0.3em">
			                Vision Foundation Model.
			            </li>
			            <li style="margin-top: 0.3em">
			                Efficiency in LVLMs and propose SparseVLM.
			            </li>
			        </ul>
				</td>
				<td align="center" style="padding:2px 20px;width:25%;vertical-align:middle"><img src='fig/BAIR_Logo_BlueType_Tag.png' width="85">
			</td>
		</tr>
	</tbody>
</table>
	    
<table style="margin-top: 0em;" width="100%" align="center" border="0" cellpadding="5">
	<tbody>
		<tr>
			<td width="75%" valign="middle">
				<papertitle><a href="https://team.doubao.com/en/">ByteDance Seed Foundation Model</a>, Beijing, China</papertitle>
				<div style="display: flex; justify-content: space-between; font-style: italic;">
				    <div> (S1) Researcher  (Advisor: <a href="https://scholar.google.com/citations?user=hql67boAAAAJ&hl=en">Haoyuan Guo</a>). </a> <br>
					  (S2) Research Intern  (Advisor: <a href="https://lu-m13.github.io/">Ming Lu</a>).
					  <br> Jul. 2023 – Jul. 2024, Jan. 2025 – Now </br>
				    </div>	
				</div>
			        <ul>
			            <li style="margin-top: 0.3em">
			                Vision Foundation Model.
			            </li>
			            <li style="margin-top: 0.3em">
			                Research on Consistency in LVLMs and propose <a href="https://seed.bytedance.com/en/public_papers/unveiling-the-tapestry-of-consistency-in-large-vision-language-models?view_from=research">ConBench</a>.
			            </li>
			        </ul>
				</td>
				<td align="center" style="padding:2px 20px;width:25%;vertical-align:middle"><img src='fig/bytedance.png' width="85">
			</td>
		</tr>
	</tbody>
</table>

<table style="margin-top: 0em;" width="100%" align="center" border="0" cellpadding="5">
	<tbody>
		<tr>
			<td width="75%" valign="middle">
				<papertitle><a href="https://damo.alibaba.com/?lang=en">Alibaba DAMO Academy</a>, Beijing, China</papertitle>
				<div style="display: flex; justify-content: space-between; font-style: italic;">
				    <div> Research Intern  (Advisor: <a href="http://cwhgn.github.io/">Weihua Chen</a>). </a>
					  <br> Jun. 2022 – Feb. 2023 </br>
				    </div>	
				</div>
			        <ul>
			            <li style="margin-top: 0.3em">
			                Research on knowledge distillation (KD) and propose AvatarKD.
			            </li>
			            <li style="margin-top: 0.3em">
			                Distill for DAMO-YOLO.
			            </li>
			        </ul>
				</td>
				<td align="center" style="padding:2px 20px;width:25%;vertical-align:middle"><img src='fig/DAMO.png' width="107">
			</td>
		</tr>
	</tbody>
</table>
<table style="margin-top: 0em;" width="100%" align="center" border="0" cellpadding="5">
	<tbody>
		<tr>
			<td width="75%" valign="middle">
				<papertitle><a href="https://sensetime.com">SenseTime Research</a>, Beijing, China</papertitle>
				<div style="display: flex; justify-content: space-between; font-style: italic;">
				    <div>Research Intern  (Advisor: <a href="https://taohuang.info/">Tao Huang</a>). </a>
					  <br> Mar. 2022 – Jun. 2022 </br>
				    </div>	
				</div>
			        <ul>
			            <li style="margin-top: 0.3em">
			                Research on knowledge distillation (KD) and propose MasKD.
			            </li>
			            <li style="margin-top: 0.3em">
			                Develop on MMRazor.
			            </li>
			        </ul>
				</td>
				<td align="center" style="padding:2px 20px;width:25%;vertical-align:middle"><img src='fig/sensetime.png' width="128">
			</td>
		</tr>
	</tbody>
</table>

<h2 style="margin-top: -1em;">Academic Services</h2>
<b>Reviewer for Conferences:</b>
<ul>
    <li style="margin-top: 0.2em">
        <b>CVPR</b> 2024 | <b>ECCV</b> 2024 | <b>ACM MM</b> 2024 | <b>NeurIPS</b> 2024
    </li>
    <li style="margin-top: 0.2em">
        <b>ICLR</b> 2025 | <b>AISTATS</b> 2025 | <b>CVPR</b> 2025 | <b>ICML</b> 2025 | <b>ICCV</b> 2025 | <b>NeurIPS</b> 2025
    </li>
    <li style="margin-top: 0.2em">
        <b>WACV</b> 2026 | <b>AAAI</b> 2026 | <b>AISTATS</b> 2026 | <b>ICLR</b> 2026 | <b>CVPR</b> 2026
    </li>
</ul>

<b>Reviewer for Journals:</b>
<ul>
    <li style="margin-top: 0.2em">
        <b>T-IP</b> | <b>T-MLR</b> | <b>T-MM</b> |<b>T-CSVT</b> | <b>T-NNLS</b>
    </li>
</ul>

<h2 style="margin-top: -1em;">Open Source Projects</h2>
<ul>

	<li>
        <a href="https://github.com/Gumpest/YOLOv5-Multibackbone-Compression">YOLOv5-Multibackbone-Compression</a><br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Duty: Owner.</div>
            <div style="margin-left: 2px;">Oct. 2021 – Mar. 2022</div>
        </div>
	Description: YOLOv5 Series Multi-backbone(TPH-YOLOv5, Ghostnet, ShuffleNetv2, Mobilenetv3Small, EfficientNetLite, PP-LCNet, SwinTransformer YOLO), 
	Module(CBAM, DCN), Pruning (EagleEye, Network Slimming), Quantization (MQBench) and Deployment (TensorRT, ncnn) Compression Tool Box.<br />
	<iframe src="https://ghbtns.com/github-btn.html?user=Gumpest&repo=YOLOv5-Multibackbone-Compression&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
	</li>

	<li>
        <a href="https://github.com/tinyvision/DAMO-YOLO">DAMO-YOLO</a><br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Duty: Distill and Deployment.</div>
            <div style="margin-left: 2px;">Jun. 2022 – Sep. 2022</div>
        </div>
	Description: First make distillation great again on all size models of YOLO series (1.0 AP+), especially on the small size.<br />
	<iframe src="https://ghbtns.com/github-btn.html?user=tinyvision&repo=DAMO-YOLO&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
	</li>
</ul>

<h2 style="margin-top: -1em;">Awards and Honor</h2>
<ul>
	<li>
        Tencent Scholarship <br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
	    <div>Ph.D. period (¥ 20,000).</div>	
            <div style="margin-right: 2px;">Sep. 2025</div>
        </div>
	</li>
	<li>
        Excellent Graduate of Peking University<br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
	    <div>Master period (Top 5% in school).</div>	
            <div style="margin-right: 2px;">June 2023</div>
        </div>
	</li>
	<li>
        National Scholarship of China <br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
	    <div>Master period (¥ 20,000).</div>	
            <div style="margin-right: 2px;">Nov. 2021</div>
        </div>
	</li>
	<li>
        National Scholarship of China <br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
	    <div>Undergraduate period (¥ 8,000).</div>
            <div style="margin-right: 2px;">Nov. 2018</div>
        </div>
	</li>
</ul>	

<h2 style="margin-top: -1em;">Visitors</h2>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=53IqZwoIImQV5s-5apExUkXvB1IyVVtE-c4Z3rFA3P4&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>

<div id="footer">
	<div id="footer-text" style="text-align: center;">
		© Yuan Zhang | Last updated: Nov. 15, 2025
	</div>
</div>

</body>

<script>
    var coll = document.getElementsByClassName("collapsible");
    var i;

    for (i = 0; i < coll.length; i++) {
        coll[i].addEventListener("click", function() {
            this.classList.toggle("active");
            var content = this.nextElementSibling;
            if (content.style.display === "block") {
            content.style.display = "none";
            } else {
            content.style.display = "block";
            }
        });
    }
</script>

<script>
function toggleAuthors(el) {
  const shortText = el.dataset.short;
  const fullText = el.dataset.full;

  el.innerText =
    el.innerText === shortText
      ? fullText
      : shortText;
}
</script>


</html>


















